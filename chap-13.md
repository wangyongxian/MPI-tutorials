<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

# 第13章 组通信MPI程序设计

MPI组通信和点到点通信的一个重要区别，就在于它需要一个特定组内的所有进程同时参加通信，而不是象点到点通信那样只涉及到发送方和接收方两个进程。组通信在各个不同进程的调用形式完全相同，而不象点到点通信那样在形式上就有发送和接收的区别。本章主要介绍如何使用MPI提供的各种组通信功能，方便编程，提高程序的可读性和移植性，提高通信效率。

## 13.1 组通信概述

组通信由哪些进程参加，以及组通信的上下文，都是由该组通信调用的通信域限定的。组通信调用可以和点对点通信共用一个通信域，MPI保证由组通信调用产生的消息不会和点对点调用产生的消息相混淆。在组通信中不需要通信消息标志参数，如果将来的MPI新版本定义了非阻塞的组通信函数，也许那时就需要引入消息标志来防止组通信彼此之间造成的混淆。

组通信一般实现三个功能：通信、同步和计算。通信功能主要完成组内数据的传输，而同步功能实现组内所有进程在特定的地点在执行进度上取得一致，计算功能稍微复杂一点，要对给定的数据完成一定的操作。

### 13.1.1 组通信的消息通信功能

对于组通信，按通信的方向的不同，又可以分为以下三种：一对多通信，多对一通信和多对多通信。

如图50所示的一对多通信，其中一个进程向其它所有的进程发送消息，一般地，把这样的进程称为ROOT，在一对多的组通信中，调用的某些参数只对ROOT有意义，对其它的进程只是满足语法的要求。广播是最常见的一对多通信的例子。

同样对于多对一通信，一个进程从其它所有的进程接收消息，这样的进程也称为ROOT，收集是最常见的多对一通信的例子。

图52所示的是多对多通信，其中每一个进程都向其它所有的进程发送消息，或者每个进程都从其它所有的进程接收消息，或者每个进程都同时向所有其它的进程发送和从其它所有的进程接收消息。

一个进程完成了它自身的组通信调用返回后，就可以释放数据缓冲区或使用缓冲区中的数据，但是一个进程组通信的完成并不表示其它所有进程的组通信都已完成，即组通信并不一定意味着同步的发生（当然同步组通信调用除外）。
  
### 13.1.2 组通信的同步功能

同步是许多应用中必须提供的功能，组通信还提供专门的调用以完成各个进程之间的 同步，从而协调各个进程的进度和步伐。

如图53所示，所有的进程并行执行，但是不同的进程执行的进度是不同的。在本例中，进程0首先执行到同步调用，执行同步操作，但是，由于其它的进程还没有到达同步调用点，因此进程0只好等待；接下来是其它的进程（如进程N-1）陆续到达同步调用点，但是，只要有一个进程未到达同步调用点，则所有其它已到达同步调用点的进程都必须得等待；当最后到达同步调用点的进程——进程1到达同步调用点后，它也执行了同步调用操作，这时，由于所有的进程都执行了这一操作，因此，它们此时才可以从同步调用返回，继续并行执行下面的操作。
 
同步的作用是当进程完成同步调用后，可以保证所有的进程都已执行了同步点前面的操作。

### 13.1.3 组通信的计算功能

组通信除了能够完成通信和同步的功能外，还可以进行计算，完成计算的功能。从效果上，可以认为，MPI组通信的计算功能是分三步实现的：①首先是通信的功能，即消息根据要求发送到目的进程，目的进程也已经接收到了各自所需要的消息；②然后是对消息的处理，即计算部分，MPI组通信有计算功能的调用都指定了计算操作，用给定的计算操作对接收到的数据进行处理；③最后一步是将处理结果放入指定的接收缓冲区。

## 13.2 广播 (MPI_BCAST)

MPI_BCAST是“一对多”组通信的典型例子，它完成从一个标识为root的进程将一条消息广播发送到组内的所有其它的进程，同时也包括它本身在内。在执行该调用时组内所有进程（不管是root进程本身还是其它的进程）都使用同一个通信域comm和根标识root，其执行结果是将根进程通信消息缓冲区中的消息拷贝到其他所有进程中去。

一般说来，数据类型datatype可以是预定义数据类型或派生数据类型，其它进程中指定的通信元素个数count、数据类型datatype必须和根进程中的指定的通信元素个数count、数据类型datatype保持一致。即对于广播操作调用，不管是广播消息的根进程，还是从根接收消息的其它进程，在调用形式上完全一致，即指明相同的根、相同的元素个数以及相同的数据类型。除MPI_BCAST之外，其它完成通信功能的组通信调用都有此限制。

## 13.3 收集 (MPI_GATHER/MPI_GATHERV)

收集MPI_GATHER是典型的“多对一”通信的例子。在收集调用中，每个进程（包括根进程本身）将其发送缓冲区中的消息发送到根进程，根进程根据发送进程的进程标识的序号（即进程的rank值）将它们各自的消息依次存放到自已的消息缓冲区中，和广播调用不同的是，广播出去的数据都是相同的，但对于收集操作，虽然从各个进程收集到的数据的个数必须相同，但从各个进程收集到的数据一般是互不相同的。其结果就象一个进程组中的N个进程（包括括根进程在内）都执行了一个发送调用，同时根进程执行了N次接收调用。

对于所有非根进程，接收消息缓冲区被忽略，但是各个进程必须提供这一参数。

收集调用每个进程的发送数据个数sendcount和发送数据类型sendtype都是相同的，都和根进程中接收数据个数recvcount和接收数据类型recvtype相同。注意根进程中指定的接收数据个数是指从每一个进程接收到的数据的个数，而不是总的接收个数。

此调用中的所有参数对根进程来说都是有意义的,而对于其它进程只有sendbuf、sendcount、sendtype、root和comm是有意义的。其它的参数虽然没有意义，但是却不能省略。root和comm在所有进程中都必须是一致的。


MPI_GATHERV和MPI_GATHER的功能类似，也完成数据收集的功能，但是它可以从不同的进程接收不同数量的数据。为此，接收数据元素的个数recvcounts是一个数组，用于指明从不同的进程接收的数据元素的个数。根进程从每一个进程接收的数据元素的个数可以不同，但是发送和接收的个数必须一致。除此之外，它还为每一个接收消息在接收缓冲区的位置提供了一个位置偏移displs数组，用户可以将接收的数据存放到根进程消息缓冲区的任意位置。也就是说，MPI_GATHERV明确指出了从不同的进程接收数据元素的个数以及这些数据在ROOT的接收缓冲区存放的起始位置，这是它相对于MPI_GATHER灵活的地方，也是比 MPI_GATHER复杂的地方。

此调用中的所有参数对根进程来说都是有意义的，而对于其它的进程只有sendbuf、sendcount、sendtype、root和comm是有意义的。参数root和comm在所有进程中都必须是一致。

## 13.4 散发 (MPI_SCATTER/MPI_SCATTERV)

MPI_SCATTER是“一对多”的组通信调用，但是和广播不同，ROOT向各个进程发送的数据可以是不同的。MPI_SCATTER和MPI_GATHER的效果正好相反，两者互为逆操作。

对于所有非根进程，发送消息缓冲区被忽略。根进程中的发送数据元素个数sendcount和发送数据类型sendtype必须和所有进程的接收数据元素个数recvcount和接收数据类型recvtype相同。根进程发送元素个数指的是发送给每一个进程的数据元素的个数，而不是总的数据个数。这就意味着在每个进程和根进程之间，发送的数据个数必须和接收的数据个数相等。

此调用中的所有参数对根进程来说都是有意义的，而对于其他进程来说，只有recvbuf、recvcount、recvtype、root和comm是有意义的。参数root和comm在所有进程中都必须是一致的。


MPI_GATHER有一个更灵活的形式MPI_GATHERV，MPI_SCATTER也有一个更灵活的 形式MPI_SCATTERV。正如MPI_SCATTER是MPI_GATHER的逆操作一样，MPI_SCATTERV是MPI_GATHERV的逆操作。

MPI_SCATTERV对MPI_SCATTER的功能进行了扩展，它允许ROOT向各个进程发送个数不等的数据，因此要求sendcounts是一个数组。同时还提供一个新的参数displs，指明根进 程发往其它不同进程的数据在根发送缓冲区中的偏移位置。对于所有非根进程，发送消息缓冲区被忽略。根进程中sendcount[i]和sendtype的类型必须和进程i的recvcount和recvtype的类型相同，这就意谓着在每个进程和根进程之间，发送的数据量必须和接收的数据量相等。

此调用中的所有参数对根进程来说都是很重要的，而对于其他进程来说只有recvbuf、recvcount、recvtype、root和comm是必不可少的。参数root和comm在所有进程中都必须是一致的。

## 13.5 组收集 (MPI_ALLGATHER/MPI_ALLGATHERV)

MPI_GATHER是将数据收集到ROOT进程，而MPI_ALLGATHER相当于每一个进程都作为ROOT执行了一次MPI_GATHER调用，即每一个进程都收集到了其它所有进程的数据。从参数上看，MPI_ALLGATHER和MPI_GATHER完全相同，只不过在执行效果上，当MPI_GATHER执行结束后，只有ROOT进程的接收缓冲区有意义；而MPI_ALLGATHER调用 结束后，所有进程的接收缓冲区都有意义，它们接收缓冲区的内容是相同的。

由MPI_ALLGATHER和MPI_GATHER的关系，不难得知MPI_ALLGATHERV和MPI_GATHERV的关系。MPI_ALLGATHERV也是所有的进程都将接收结果，而不是只有根进程接收结果。从每个进程发送的第j块数据将被所有进程接收，然后存放在各个进程接收消息缓冲区recvbuf的第j块中。进程j的sendcount和sendtype的类型必须和其他所有进程的recvcounts[j]和recvtype相同。

## 13.6 全互换 (MPI_ALLTOALL)

MPI_ALLTOALL是组内进程之间完全的消息交换，其中每一个进程都向其它所有的进程发送消息，同时，每一个进程都从其它所有的进程接收消息。

前面介绍的MPI_ALLGATHER调用中，每个进程散发一个相同的消息给所有的进程，而这里的MPI_ALLTOALL散发给不同进程的消息是不同的，因此它的发送缓冲区也是一个数组。MPI_ALLTOALL的每个进程可以向所有接收者发送数目不同的数据。第i个进程发送的第j块数据将被第j个进程接收，并存放在其接收消息缓冲区recvbuf的第i块中。每个进程的sendcount和sendtype的类型必须和所有其他进程的recvcount和recvtype相同，这就意谓着在每个进程和根进程之间，发送的数据量必须和接收的数据量相等。

调用MPI_ALLTOALL，相当于每个进程依次将它的发送缓冲区的第i块数据发送给第i个进程，同时每个进程又都依次从第j个进程接收数据放到各自接收缓冲区的第j块数据区的位置。

从图中可以看出，在互换之前依次将各进程的发送缓冲区组织在一起，互换之后依次将各进程的接收缓冲区组织在一起，则接收缓冲区组成的矩阵是发送缓冲区组成的矩阵的转置（若每次向一个进程发送的数据是多个，则将这多个数据看作是一个数据单元）。

## 13.7 同步 (MPI_BARRIER)

MPI_BARRIER阻塞所有的调用者，直到所有的组成员都调用了它，各个进程中这个调用才可以返回。

## 13.8 归约 (MPI_REDUCE)

MPI_REDUCE将组内每个进程输入缓冲区中的数据按给定的操作op进行运算，并将其结果返回到序列号为root的进程的输出缓冲区中。输入缓冲区由参数sendbuf、count和datatype定义，输出缓冲区由参数recvbuf、count和datatype定义，要求两者的元素数目和类型都必须相同。因为所有组成员都用同样的参数count、datatype、op、root和comm来调用此例程，故而所有进程都提供长度相同、元素类型相同的输入和输出缓冲区。每个进程可能提供一个元素或一系列元素，组合操作依次针对每个元素进行。

操作op始终被认为是可结合的，并且所有MPI定义的操作被认为是可交换的。用户自定义的操作被认为是可结合的，但可以不是可交换的。

## 13.9 MPI预定义的归约操作

MPI中已经定义好的一些操作，它们是为函数MPI_REDUCE和一些其他的相关函数，如MPI_ALLREDUCE、MPI_REDUCE_SCATTER和MPI_SCAN而定义的。这些操作用来设定相应的op。

表9 MPI预定义的归约操作
  
|名字               |含义                |
|:----------------|:-------------------|
|MPI_MAX          |最大值               |
|MPI_MIN          |最小值               |
|MPI_SUM          |求和                 |
|MPI_PROD         |求积                 |
|MPI_LAND         |逻辑与               |
|MPI_BAND         |按位与               |
|MPI_LOR          |逻辑或               |
|MPI_BOR          |按位或               |
|MPI_LXOR         |逻辑异或             |
|MPI_BXOR         |按位异或             |
|MPI_MAXLOC       |最大值且相应位置       |
|MPI_MINLOC       |最小值且相应位置       |

MPI_MINLOC和MPI_MAXLOC这两个操作将在???节中分别讨论。下面列出MPI中定义的其他有关于op和datatype参数的操作，以及它们之间允许的组合。
首先列出基本数据类型组：

表格10 C或FORTRAN类型与MPI类型的对应

|C或FORTRAN类型     |相应的MPI定义类型 |
|:-----------------|:--------------|
|C语言中的整型|MPI_INT MPI_LONG MPI_SHORT MPI_UNSIGNED_SHORT MPI_UNSIGNED MPI_UNSIGNED_LONG |
|Fortran语言中的整型|MPI_INTEGER |
|浮点数|MPI_FLOAT MPI_DOUBLE MPI_REAL MPI_DOUBLE_PRECISION MPI_LONG_DOUBLE|
|逻辑型|MPI_LOGICAL|
|复数型|MPI_COMPLEX|
|字节型|MPI_BYTE|

对每种操作允许的数据类型如下：

表格11 归约操作与相应类型的对应关系

|操作|允许的数据类型|
|:--|:----------|
|MPI_MAX, MPI_MIN|C整数, Fortran整数, 浮点数|
|MPI_SUM, MPI_PROD|C整数, Fortran整数, 浮点数, 复数|
|MPI_LAND, MPI_LOR, MPI_LXOR|C整数, 逻辑型|
|MPI_BAND, MPI_BOR, MPI_BXOR|C整数, Fortran整数, 字节型|


## 13.10 求π值

## 13.11 组归约 (MPI_ALLREDUCE)

只要理解了归约操作，就可以很容易地掌握组归约操作。组归约MPI_ALLREDUCE就相当于组中每一个进程都作为ROOT分别进行了一次归约操作。即归约的结果不只是某一个进程拥有，而是所有的进程都拥有。它在某种程度上和组收集与收集的关系很相似。

## 13.12 归约并散发 (MPI_REDUCE_SCATTER)

MPI_REDUCE_SCATTER操作可以认为是MPI对每个归约操作的变形，它将归约结果分散到组内的所有进程中去，而不是仅仅归约到ROOT进程。

MPI_REDUCE_SCATTER对由sendbuf、count和datatype定义的发送缓冲区数组的元素逐个进行归约操作，发送缓冲区数组的长度count等于所有进程i的irecvcount[i]之和。然后，将结果数组的前recvcounts[0]个元素送给进程0的接收缓冲区，再将接下来的recvcounts[1]个元素送给进程1的接收缓冲区，依次类推，将最后的recvcounts[N-1]个元素送给进程N-1的接收缓冲区。

## 13.13 扫描 (MPI_SCAN)

可以将扫描看作是一种特殊的归约，即每一个进程都对排在它前面的进程进行归约操作。MPI_SCAN调用的结果是，对于每一个进程i，它对进程0, ..., i的发送缓冲区的数据进行指定的归约操作，结果存入进程i的接收缓冲区。

也可以换一个角度，将扫描操作看作是每一个进程i发送缓冲区中的数据与它前面的进程i-1接收缓冲区中的数据进行指定的归约操作后，将结果存入进程i的接收缓冲区；而进程i接收缓冲区中的数据用来和进程i+1发送缓冲区中的数据进行归约。进程0接收缓冲区中的数据就是发送缓冲区的数据。

## 13.14 不同类型归约操作的简单对比

本节对归约操作、组归约操作和归约并散发操作进行简单地对比，希望通过对比中能加深对各种类型归约操作的理解，并正确使用各种类型归约操作。

归约操作的效果就是接收缓冲区中数据的改变，而接收缓冲区中数据的改变是直接与各个进程发送缓冲区中的数据密切相关的。下面就不同类型归约前后各个进程发送缓冲区与接收缓冲区中数据的关系，来说明归约操作的最终效果。

简单的归约操作只有ROOT进程的接收缓冲区在归约后其内容有意义，而其它进程接收缓冲区中的内容没有意义。ROOT进程接收缓冲区中的数据需要所有进程发送缓冲区中的数据进行指定的运算后才能够得到。ROOT进程的接收缓冲区和各个进程的发送缓冲区大小是一样的。

而组归约完成后所有进程中接收缓冲区的内容都有意义，都是对其它所有进程发送缓冲区中的数据进行指定的运算之后的结果。各个进程接收缓冲区中的内容是相同的。对于组归约，各进程发送缓冲区和接收缓冲区的大小相同。

归约并散发操作较前面两种操作更复杂一些。它在执行归约操作的同时将归约的结果散发到不同进程的接收缓冲区中。在效果上，就如同先使某一个进程作为ROOT进程执行归约操作，然后ROOT进程再将归约的结果放到发送缓冲区中，执行散发操作。对于归约并散发操作，各进程的接收缓冲区的大小是发送缓冲区大小的1/N（N为总的进程个数）。

扫描操作可以认为是每一个进程都执行了一次归约操作，只要理解了归约操作，就很容易理解扫描操作。扫描操作各个进程的发送缓冲区和接收缓冲区的大小相同。

## 13.15 不正确的组通信方式

无论组通信是同步的还是异步的，一个正确的、可移植调用组通信的程序都不应引起死锁。

## 13.16 MINLOC和MAXLOC

MPI_MINLOC操作符用于计算全局最小值和这个最小值的索引号，MPI_MAXLOC操作符用于计算全局最大值和这个最大值的索引号。这两个函数的一个用途是计算一个全局最小值/最大值和这个值所在的进程序号。

两个操作都是可结合、可交换的。如将MPI_MAXLOC应用于\\((u_0,0), (u_1,1), \\cdots, (u_{n-1},n-1)\\)这个序列上进行归约，那么返回结果\\((u,r)\\)满足
